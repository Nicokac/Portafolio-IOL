# Operaciones y Observabilidad

Este documento describe el flujo operativo para monitorear y mantener la
aplicaci√≥n de Portafolio IOL con foco en la visibilidad expuesta en el panel
**"üîç Estado del Sistema"** y los diagn√≥sticos autom√°ticos.

## Monitoreo de rendimiento

Un job en segundo plano ejecuta benchmarks peri√≥dicos sobre los endpoints
cr√≠ticos (`/predictive_compute`, `/quotes_refresh`, `/apply_filters` y otros
instrumentados) y registra los resultados en ``logs/system_diagnostics.log``.
Cada ciclo calcula el promedio de latencia reciente y lo compara con la media
hist√≥rica. Si la m√©trica actual duplica (o supera 2√ó) la media previa, el panel
marca la condici√≥n como degradada.

Adem√°s del promedio de latencias, el snapshot incluye:

* Estado del cach√© predictivo (hits, misses, hit ratio, TTL efectivo y TTL
  restante).
* Validaci√≥n de claves Fernet obligatorias (`FASTAPI_TOKENS_KEY` e
  `IOL_TOKENS_KEY`) con un *fingerprint* seguro para identificar cambios.
* Informaci√≥n del entorno de ejecuci√≥n (APP_ENV, zona horaria, versi√≥n de
  Python y plataforma).

Para acceder a estos datos desde la UI abr√≠ **"üîé Diagn√≥stico del sistema"** en
la barra lateral. El panel muestra las latencias promedio, posibles
degradaciones y un resumen del cach√© y las claves Fernet. El archivo de log
permite auditar los ciclos hist√≥ricos o integrarlo a pipelines externos.

### M√©trica `ui_total_load_ms` (v0.6.6-patch10b)

La versi√≥n `v0.6.6-patch10b` alinea la visibilidad del tiempo total de carga de
la UI en los tres canales operativos principales:

* **Panel de Streamlit:** la tabla de *M√©tricas instrumentadas* muestra
  `total_load_ms`, alimentada directamente por `st.session_state`. √ötil para
  validar mejoras sin abandonar la vista de diagn√≥stico.
* **Endpoint `/metrics`:** el backend expone un gauge `ui_total_load_ms` dentro
  del registro Prometheus compartido. El valor se actualiza al finalizar cada
  render exitoso y publica `NaN` en ejecuciones headless donde la sesi√≥n de UI no
  existe.
* **logs/app_startup.log:** se agrega una l√≠nea JSON con los campos
  `{metric, value_ms, version, timestamp}` al completarse la primera renderizaci√≥n.
  Esto permite correlacionar startups lentos con despliegues o migraciones.

Objetivos de operaci√≥n sugeridos:

* **< 10‚ÄØ000 ms:** escenario nominal.
* **10‚ÄØ000‚Äì15‚ÄØ000 ms:** advertencia, revisar latencias de dependencias.
* **> 15‚ÄØ000 ms:** cr√≠tico, disparar alerta y escalar al equipo de backend.

### Secuencia de arranque y m√©trica `ui_startup_load_ms`

El arranque inicial sigue un orden estricto para maximizar el *time-to*
*interactive* del login:

1. **Validaci√≥n de seguridad:** `shared.security_env_validator.validate_security_environment`
   corre una √∫nica vez, marca `_security_validated` en `st.session_state` y detiene la
   ejecuci√≥n ante claves inv√°lidas.
2. **Preload asincr√≥nico:** `services.preload_worker.start_preload_worker` inicia un
   hilo *daemon* que importa `pandas`, `plotly` y `statsmodels` mientras la UI sigue
   respondiendo.
3. **Login interactivo:** `ui.login.render_login_page` renderiza la pantalla y
   persiste `ui_startup_load_ms` con el tiempo transcurrido desde `_TOTAL_LOAD_START`.
4. **Inicializaci√≥n post-auth:** una vez autenticado el usuario, `app._schedule_post_login_initialization`
   prepara m√©tricas, mantenimiento SQLite y diagn√≥sticos en segundo plano.

El valor de `ui_startup_load_ms` queda visible en el panel **"üîé Diagn√≥stico del sistema"**
junto a `ui_total_load_ms`, y se publica en Prometheus como gauge hom√≥nimo.
Para consultarlo manualmente:

* **Prometheus:** solicit√° `/metrics` y busc√° la l√≠nea `ui_startup_load_ms <valor>`.
* **UI:** abr√≠ la secci√≥n "üïí Tiempos de arranque" dentro del panel de diagn√≥stico para ver
  el √∫ltimo registro en milisegundos.

## Panel de estado

La UI de Streamlit ofrece un panel dedicado con las siguientes secciones:

* **Performance:** m√©tricas Prometheus de tiempos de ejecuci√≥n, latencia y
  volumen de solicitudes.
* **Seguridad:** estado del token de autenticaci√≥n emitido por la UI y contadores
  de refrescos, fallas y revocaciones.
* **Cach√©:** indicadores de eficiencia del cach√© predictivo, incluyendo hit ratio
  y eventos de invalidaci√≥n.

Se recomienda revisar peri√≥dicamente los indicadores clave expuestos en los
cards superiores del panel:

| Indicador | Descripci√≥n |
| --- | --- |
| **Uptime** | Tiempo transcurrido desde el √∫ltimo arranque del backend instrumentado por Prometheus. |
| **Refresh tokens** | Cantidad acumulada de renovaciones exitosas del token backend. |
| **Hit ratio cach√©** | Porcentaje de aciertos sobre el cach√© predictivo. Valores menores al 70¬†% requieren investigaci√≥n. |

### Worker predictivo asincr√≥nico

Las simulaciones sectoriales ahora se ejecutan a trav√©s de un worker en segundo
plano definido en `application/predictive_jobs`. Cada solicitud publica un job
identificado por `job_id`; la UI muestra el √∫ltimo resultado cacheado y un
spinner con el estado (`pending`, `running`, `failed`).

* El TTL del resultado se sincroniza con `MarketDataCache.resolve_prediction_ttl`
  para evitar drift entre el cache y el worker.
* Consult√° el estado en caliente mediante la funci√≥n
  `application.predictive_service.predictive_job_status(job_id)`.
* Cuando el job finaliza, las m√©tricas de latencia (`predictive_job_latency`) se
  registran junto con los contadores de hits/misses existentes.

## Gesti√≥n del token de autenticaci√≥n

La UI emite un token Fernet con TTL m√°ximo configurado por `FASTAPI_AUTH_TTL`
(por defecto 15 minutos). El panel muestra:

* Usuario asociado (con ofuscaci√≥n b√°sica).
* Timestamp de emisi√≥n y expiraci√≥n calculados con la zona horaria
  `America/Argentina/Buenos_Aires`.
* Tiempo restante de vida (TTL restante).

### Refresh manual

Us√° el bot√≥n **"üîÑ Refrescar token"** cuando:

1. Est√©s ejecutando workflows prolongados y desees evitar la expiraci√≥n del
   token en medio del proceso.
2. Detectes advertencias de proximidad a la expiraci√≥n en los logs o en el
   backend.

Al refrescar de manera manual se emite un nuevo token y se actualiza el
timestamp visible en la UI. Si el refresh falla, consult√° los logs del backend
(`analysis.log`) o el historial de observabilidad en la secci√≥n de performance.

## Alertas y troubleshooting

* **Latencias elevadas:** el tablero de performance incluye percentiles y
  filtros por bloque para identificar cuellos de botella. Revis√° los registros
  exportables (`performance_metrics.csv`/`.json`).
* **Cache hit ratio bajo:** verific√° que los jobs de precarga est√©n activos y
  que la caducidad (`TTL`) sea acorde. Revis√° `docs/cache_management.md` para
  estrategias de warmup.
* **Errores de autenticaci√≥n:** inspeccion√° los contadores `auth_*` y
  confirm√° el estado del token. En caso de revocaci√≥n manual, gener√° un nuevo
  token desde la pantalla de login.

Consult√° tambi√©n `docs/troubleshooting.md` para gu√≠as espec√≠ficas de resoluci√≥n
de incidentes.

