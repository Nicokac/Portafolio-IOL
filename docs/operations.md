# Operaciones y Observabilidad

Este documento describe el flujo operativo para monitorear y mantener la
aplicaci√≥n de Portafolio IOL con foco en la visibilidad expuesta en el panel
**"üîç Estado del Sistema"** y los diagn√≥sticos autom√°ticos.

## Monitoreo de rendimiento

Un job en segundo plano ejecuta benchmarks peri√≥dicos sobre los endpoints
cr√≠ticos (`/predictive_compute`, `/quotes_refresh`, `/apply_filters` y otros
instrumentados) y registra los resultados en ``logs/system_diagnostics.log``.
Cada ciclo calcula el promedio de latencia reciente y lo compara con la media
hist√≥rica. Si la m√©trica actual duplica (o supera 2√ó) la media previa, el panel
marca la condici√≥n como degradada.

Adem√°s del promedio de latencias, el snapshot incluye:

* Estado del cach√© predictivo (hits, misses, hit ratio, TTL efectivo y TTL
  restante).
* Validaci√≥n de claves Fernet obligatorias (`FASTAPI_TOKENS_KEY` e
  `IOL_TOKENS_KEY`) con un *fingerprint* seguro para identificar cambios.
* Informaci√≥n del entorno de ejecuci√≥n (APP_ENV, zona horaria, versi√≥n de
  Python y plataforma).

Para acceder a estos datos desde la UI abr√≠ **"üîé Diagn√≥stico del sistema"** en
la barra lateral. El panel muestra las latencias promedio, posibles
degradaciones y un resumen del cach√© y las claves Fernet. El archivo de log
permite auditar los ciclos hist√≥ricos o integrarlo a pipelines externos.

### M√©trica `ui_total_load_ms` (v0.6.6-patch10b)

La versi√≥n `v0.6.6-patch10b` alinea la visibilidad del tiempo total de carga de
la UI en los tres canales operativos principales:

* **Panel de Streamlit:** la tabla de *M√©tricas instrumentadas* muestra
  `total_load_ms`, alimentada directamente por `st.session_state`. √ötil para
  validar mejoras sin abandonar la vista de diagn√≥stico.
* **Endpoint `/metrics`:** el backend expone un gauge `ui_total_load_ms` dentro
  del registro Prometheus compartido. El valor se actualiza al finalizar cada
  render exitoso y publica `NaN` en ejecuciones headless donde la sesi√≥n de UI no
  existe.
* **logs/app_startup.log:** se agrega una l√≠nea JSON con los campos
  `{metric, value_ms, version, timestamp}` al completarse la primera renderizaci√≥n.
  Esto permite correlacionar startups lentos con despliegues o migraciones.

Objetivos de operaci√≥n sugeridos:

* **< 10‚ÄØ000 ms:** escenario nominal.
* **10‚ÄØ000‚Äì15‚ÄØ000 ms:** advertencia, revisar latencias de dependencias.
* **> 15‚ÄØ000 ms:** cr√≠tico, disparar alerta y escalar al equipo de backend.

### Secuencia de arranque y m√©trica `ui_startup_load_ms`

El arranque inicial sigue un orden estricto para maximizar el *time-to*
*interactive* del login:

1. **Validaci√≥n de seguridad:** `shared.security_env_validator.validate_security_environment`
   corre una √∫nica vez, marca `_security_validated` y aborta si faltan secretos.
2. **Preload pausado:** `_render_login_phase()` arranca
   `start_preload_worker(paused=True)`, marca `scientific_preload_ready=False` y
   muestra la pantalla de login sin dependencias pesadas.
3. **Login interactivo:** `ui.login.render_login_page` registra
   `ui_startup_load_ms` al quedar visible la pantalla.
4. **Reanudaci√≥n cient√≠fica:** `_schedule_scientific_preload_resume()` se invoca
   inmediatamente despu√©s de renderizar el login para reanudar el worker con
   `resume_preload_worker(delay_seconds=0.0)`. Las vistas de an√°lisis llaman a
   `ui.helpers.preload.ensure_scientific_preload_ready`, que muestra un *spinner*
   corto hasta que el worker termina.
5. **Inicializaci√≥n post-auth:** `app._schedule_post_login_initialization`
   prepara m√©tricas, mantenimiento SQLite y diagn√≥sticos en segundo plano.

El valor de `ui_startup_load_ms` queda visible en el panel **"üîé Diagn√≥stico del sistema"**
junto a `ui_total_load_ms`, y se publica en Prometheus como gauge hom√≥nimo.
Para consultarlo manualmente:

* **Prometheus:** solicit√° `/metrics` y busc√° `ui_startup_load_ms`,
  `preload_total_ms` y las m√©tricas por librer√≠a
  (`preload_pandas_ms`, `preload_plotly_ms`, `preload_statsmodels_ms`).
* **UI:** abr√≠ la secci√≥n "üïí Tiempos de arranque" dentro del panel de diagn√≥stico para ver
 el √∫ltimo registro en milisegundos junto al estado de la precarga.

**Configurar la lista cient√≠fica:** el worker lee `APP_PRELOAD_LIBS` (coma
separada) si se necesita ampliar o acotar la precarga; de lo contrario usa el
tr√≠o `pandas`, `plotly`, `statsmodels`. En despliegue se fuerza
`APP_PRELOAD_LIBS=pandas,plotly` para reducir la precarga cient√≠fica. Evit√°
a√±adir `application.predictive_service` o `controllers.portfolio.charts`, que
contin√∫an import√°ndose bajo demanda v√≠a `importlib.import_module`.

**API de reanudaci√≥n (`resume_preload_worker`):**

* **Firma:** `resume_preload_worker(delay_seconds=0.0, libs_override=None)`.
* **Qui√©n la llama:** `ui.orchestrator._schedule_scientific_preload_resume` al
  terminar de renderizar la pantalla de login. Otros orquestadores pueden
  reusarla si necesitan repetir la precarga con un conjunto custom.
* **Cu√°ndo:** inmediatamente despu√©s del login exitoso o con un `delay_seconds`
  acotado cuando se desea posponer la reanudaci√≥n sin bloquear la UI.
* **Par√°metros:**
  * `libs_override`: lista opcional de m√≥dulos a precargar (ej. `("pandas",)`);
    si no se indica, se usa `APP_PRELOAD_LIBS` o el tr√≠o por defecto.
  * `delay_seconds`: demora opcional antes de disparar el `Event` que despierta
    al hilo. √ötil para coordinar con otras tareas de arranque.
* **Invariantes:** el hilo `preload_worker` es el √∫nico responsable de importar
  librer√≠as pesadas; el hilo principal solo programa la reanudaci√≥n y consulta
  `get_preload_metrics()` para leer el √∫ltimo resultado.

**M√©tricas estructuradas de precarga:** cada import registra en
`logs/app_startup.log` un JSON con `{event, module_name, duration_ms, status,
timestamp}` y un resumen final `{event:"preload_total", resume_delay_ms,
libraries}`. Estas l√≠neas permiten auditar cu√°nto demor√≥ cada m√≥dulo y cu√°ndo se
dispar√≥ la reanudaci√≥n desde la UI.

### Fase A / Fase B y alarmas

* **Fase A:** va desde `TOTAL_LOAD_START` hasta que se renderiza el login.
  El evento `login_screen_rendered` agrega `startup_ms` y `phase_a_status`
  (`ok` si < 500 ms, `alert` en caso contrario).
* **Fase B:** va desde la validaci√≥n de credenciales hasta que el worker de
  precarga marca `preload_ready=True`. El evento `startup_phase_timings` incluye
  `phase_b_ms` y `phase_b_status` (`ok` si < 1 s tras el login).
* **Inicio y fin del preload:** el evento `preload_worker_started` registra
  timestamp, librer√≠as y si qued√≥ pausado; el cierre se refleja en
  `preload_total` con `status` y `resume_delay_ms`.
* **An√°lisis renderizados:** `analysis_screen_rendered` se emite una sola vez
  por pesta√±a (portafolio, recomendaciones, comparativa, monitoreo) con el
  tiempo de arranque acumulado.
* **Arranque de la app:** `app_start` agrega una marca de tiempo inicial para
  correlacionar Fase A con el tiempo de proceso.

**Objetivos operativos:** Fase A < 500 ms y Fase B < 1000 ms tras el login. Si
se usan m√©tricas centralizadas (Prometheus o logs parseados), sugerimos:

* Panel: gr√°fico de barras apilado por `phase_a_ms` y `phase_b_ms` filtrando
  por `phase_*_status="alert"` para detectar regresiones.
* Alerta: en Prometheus, un `alert` sobre `max_over_time(ui_startup_load_ms[5m])`
  > 500 o `max_over_time(preload_total_ms[5m]) > 1000` puede encender una
  notificaci√≥n (Slack/Email). Con logs estructurados, agreg√° una regla que
  cuente eventos `phase_*_status=alert` en ventanas de 15 minutos.

**Extender `APP_PRELOAD_LIBS`:**

1. Edit√° la variable de entorno (Procfile o deployment) y a√±ad√≠ los m√≥dulos
   separados por coma: `APP_PRELOAD_LIBS=pandas,plotly,statsmodels,seaborn`.
2. Confirm√° que los nuevos imports son **puros** (sin side-effects de red) para
   que el worker no se bloquee. Si son pesados, inicializalos v√≠a
   `importlib.import_module` dentro de `services/preload_worker.py` para que
   queden instrumentados.
3. Document√° el motivo en `docs/operations.md` y, si aplica, actualiz√° las
   pantallas cient√≠ficas que dependan de la librer√≠a para mantener la lista
   sincronizada.

**Snapshot de bytecode:** durante el arranque `scripts/start.sh` ejecuta
`scripts/warmup_bytecode.py` (controlado por `ENABLE_BYTECODE_WARMUP`, habilitado
por defecto) para generar `.pyc` y reducir los costos de importaci√≥n en fr√≠o.

## Panel de estado

La UI de Streamlit ofrece un panel dedicado con las siguientes secciones:

* **Performance:** m√©tricas Prometheus de tiempos de ejecuci√≥n, latencia y
  volumen de solicitudes.
* **Seguridad:** estado del token de autenticaci√≥n emitido por la UI y contadores
  de refrescos, fallas y revocaciones.
* **Cach√©:** indicadores de eficiencia del cach√© predictivo, incluyendo hit ratio
  y eventos de invalidaci√≥n.

Se recomienda revisar peri√≥dicamente los indicadores clave expuestos en los
cards superiores del panel:

| Indicador | Descripci√≥n |
| --- | --- |
| **Uptime** | Tiempo transcurrido desde el √∫ltimo arranque del backend instrumentado por Prometheus. |
| **Refresh tokens** | Cantidad acumulada de renovaciones exitosas del token backend. |
| **Hit ratio cach√©** | Porcentaje de aciertos sobre el cach√© predictivo. Valores menores al 70¬†% requieren investigaci√≥n. |

### Worker predictivo asincr√≥nico

Las simulaciones sectoriales ahora se ejecutan a trav√©s de un worker en segundo
plano definido en `application/predictive_jobs`. Cada solicitud publica un job
identificado por `job_id`; la UI muestra el √∫ltimo resultado cacheado y un
spinner con el estado (`pending`, `running`, `failed`).

* El TTL del resultado se sincroniza con `MarketDataCache.resolve_prediction_ttl`
  para evitar drift entre el cache y el worker.
* Consult√° el estado en caliente mediante la funci√≥n
  `application.predictive_service.predictive_job_status(job_id)`.
* Cuando el job finaliza, las m√©tricas de latencia (`predictive_job_latency`) se
  registran junto con los contadores de hits/misses existentes.

## Gesti√≥n del token de autenticaci√≥n

La UI emite un token Fernet con TTL m√°ximo configurado por `FASTAPI_AUTH_TTL`
(por defecto 15 minutos). El panel muestra:

* Usuario asociado (con ofuscaci√≥n b√°sica).
* Timestamp de emisi√≥n y expiraci√≥n calculados con la zona horaria
  `America/Argentina/Buenos_Aires`.
* Tiempo restante de vida (TTL restante).

### Refresh manual

Us√° el bot√≥n **"üîÑ Refrescar token"** cuando:

1. Est√©s ejecutando workflows prolongados y desees evitar la expiraci√≥n del
   token en medio del proceso.
2. Detectes advertencias de proximidad a la expiraci√≥n en los logs o en el
   backend.

Al refrescar de manera manual se emite un nuevo token y se actualiza el
timestamp visible en la UI. Si el refresh falla, consult√° los logs del backend
(`analysis.log`) o el historial de observabilidad en la secci√≥n de performance.

## Alertas y troubleshooting

* **Latencias elevadas:** el tablero de performance incluye percentiles y
  filtros por bloque para identificar cuellos de botella. Revis√° los registros
  exportables (`performance_metrics.csv`/`.json`).
* **Cache hit ratio bajo:** verific√° que los jobs de precarga est√©n activos y
  que la caducidad (`TTL`) sea acorde. Revis√° `docs/cache_management.md` para
  estrategias de warmup.
* **Errores de autenticaci√≥n:** inspeccion√° los contadores `auth_*` y
  confirm√° el estado del token. En caso de revocaci√≥n manual, gener√° un nuevo
  token desde la pantalla de login.

Consult√° tambi√©n `docs/troubleshooting.md` para gu√≠as espec√≠ficas de resoluci√≥n
de incidentes.

